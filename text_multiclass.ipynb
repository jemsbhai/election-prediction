{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stack-overflow-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stack-overflow-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['tags'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10286120\n"
     ]
    }
   ],
   "source": [
    "print(df['post'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['java','html','asp.net','c#','ruby-on-rails','jquery','mysql','php','ios','javascript','python','c','css','android','iphone','sql','objective-c','c++','angularjs','.net']\n",
    "plt.figure(figsize=(10,4))\n",
    "df.tags.value_counts().plot(kind='bar');\n",
    "\n",
    "\n",
    "def print_plot(index):\n",
    "    example = df[df.index == index][['post', 'tags']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Tag:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to chain expressions inside ngclass when using the {...}[] form  how can i add another expression to an <code>ng-class</code> directive that uses this form:   <pre><code>ng-class= {true: loading   false: loading-done }[data.loader===null]  </code></pre>   i d like to add something like this to the list:   <pre><code>{highlight:isspecial} </code></pre>   is it possible without expanding the first expression     thanks.\n",
      "Tag: angularjs\n"
     ]
    }
   ],
   "source": [
    "print_plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text Pre-processing ####\n",
    "\n",
    "### For this particular data set, our text cleaning step includes HTML decoding, \n",
    "## remove stop words, change text to lower case, remove punctuation, \n",
    "## remove bad characters, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\localadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\localadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need interface c# possible duplicate would want use interfaces need interface want know use example interface idemo function prototype public void show first class using interface class myclass1 idemo public void show function body comes responsewrite myclass second class using interface class myclass2 idemo public void show function body comes responsewrite myclass2 responsewrite two classes function name different body even achieved without interface need interface use\n",
      "Tag: c#\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['post'] = df['post'].apply(clean_text)\n",
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.clean_text(text)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3424297"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Split ####\n",
    "\n",
    "X = df.post\n",
    "y = df.tags\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Naive Bayes ######################## \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7395\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         java       0.63      0.65      0.64       613\n",
      "         html       0.94      0.86      0.90       620\n",
      "      asp.net       0.87      0.92      0.90       587\n",
      "           c#       0.70      0.77      0.73       586\n",
      "ruby-on-rails       0.73      0.87      0.79       599\n",
      "       jquery       0.72      0.51      0.60       589\n",
      "        mysql       0.77      0.74      0.75       594\n",
      "          php       0.69      0.89      0.78       610\n",
      "          ios       0.63      0.59      0.61       617\n",
      "   javascript       0.57      0.65      0.60       587\n",
      "       python       0.70      0.50      0.59       611\n",
      "            c       0.79      0.78      0.79       594\n",
      "          css       0.84      0.59      0.69       619\n",
      "      android       0.66      0.84      0.74       574\n",
      "       iphone       0.64      0.83      0.72       584\n",
      "          sql       0.66      0.64      0.65       578\n",
      "  objective-c       0.79      0.77      0.78       591\n",
      "          c++       0.89      0.83      0.86       608\n",
      "    angularjs       0.94      0.89      0.91       638\n",
      "         .net       0.74      0.66      0.70       601\n",
      "\n",
      "     accuracy                           0.74     12000\n",
      "    macro avg       0.74      0.74      0.74     12000\n",
      " weighted avg       0.75      0.74      0.74     12000\n",
      "\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Linear Support Vector Machine ######################## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7895833333333333\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         java       0.73      0.67      0.70       613\n",
      "         html       0.84      0.94      0.89       620\n",
      "      asp.net       0.88      0.95      0.92       587\n",
      "           c#       0.81      0.80      0.80       586\n",
      "ruby-on-rails       0.73      0.89      0.80       599\n",
      "       jquery       0.77      0.39      0.52       589\n",
      "        mysql       0.81      0.69      0.74       594\n",
      "          php       0.71      0.95      0.81       610\n",
      "          ios       0.83      0.57      0.67       617\n",
      "   javascript       0.72      0.58      0.64       587\n",
      "       python       0.71      0.65      0.68       611\n",
      "            c       0.79      0.88      0.83       594\n",
      "          css       0.77      0.79      0.78       619\n",
      "      android       0.84      0.86      0.85       574\n",
      "       iphone       0.82      0.81      0.81       584\n",
      "          sql       0.70      0.68      0.69       578\n",
      "  objective-c       0.81      0.90      0.85       591\n",
      "          c++       0.84      0.96      0.90       608\n",
      "    angularjs       0.87      0.96      0.91       638\n",
      "         .net       0.78      0.88      0.83       601\n",
      "\n",
      "     accuracy                           0.79     12000\n",
      "    macro avg       0.79      0.79      0.78     12000\n",
      " weighted avg       0.79      0.79      0.78     12000\n",
      "\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################## Logistic Regression ######################## \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7819166666666667\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         java       0.70      0.62      0.66       613\n",
      "         html       0.91      0.91      0.91       620\n",
      "      asp.net       0.97      0.94      0.95       587\n",
      "           c#       0.78      0.77      0.78       586\n",
      "ruby-on-rails       0.77      0.81      0.79       599\n",
      "       jquery       0.59      0.58      0.59       589\n",
      "        mysql       0.77      0.75      0.76       594\n",
      "          php       0.82      0.85      0.83       610\n",
      "          ios       0.69      0.71      0.70       617\n",
      "   javascript       0.61      0.59      0.60       587\n",
      "       python       0.64      0.63      0.63       611\n",
      "            c       0.83      0.83      0.83       594\n",
      "          css       0.78      0.78      0.78       619\n",
      "      android       0.84      0.85      0.85       574\n",
      "       iphone       0.80      0.83      0.81       584\n",
      "          sql       0.65      0.64      0.64       578\n",
      "  objective-c       0.82      0.85      0.83       591\n",
      "          c++       0.91      0.91      0.91       608\n",
      "    angularjs       0.96      0.94      0.95       638\n",
      "         .net       0.78      0.84      0.81       601\n",
      "\n",
      "     accuracy                           0.78     12000\n",
      "    macro avg       0.78      0.78      0.78     12000\n",
      " weighted avg       0.78      0.78      0.78     12000\n",
      "\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "############### Word2vec and Logistic Regression ###############\n",
    "\n",
    "##### word2vec model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial_Hospital',\n",
       " 'Seniors',\n",
       " 'memorandum',\n",
       " 'elephant',\n",
       " 'Trump',\n",
       " 'Census',\n",
       " 'pilgrims',\n",
       " 'De',\n",
       " 'Dogs',\n",
       " '###-####_ext',\n",
       " 'chaotic',\n",
       " 'forgive',\n",
       " 'scholar',\n",
       " 'Lottery',\n",
       " 'decreasing',\n",
       " 'Supervisor',\n",
       " 'fundamentally',\n",
       " 'Fitness',\n",
       " 'abundance',\n",
       " 'Hold']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore some vocabularies\n",
    "\n",
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n",
    "\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['tags'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.tags))\n",
    "print(classification_report(test.tags, y_pred,target_names=my_tags))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Doc2vec and Logistic Regression ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "#from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    labeled = []\n",
    "    \n",
    "    x = 0\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        x += 1\n",
    "        v_split = v.split()\n",
    "        labeled.append(TaggedDocument(v_split, [label]))\n",
    "    print(x)\n",
    "    return labeled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.post, df.tags, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['fulltext', 'search', 'php', 'pdo', 'returning', 'result', 'searched', 'lot', 'matter', 'find', 'wrong', 'setup', 'trying', 'fulltext', 'search', 'using', 'pdo', 'php', 'get', 'results', 'error', 'messages', 'table', 'contains', 'customer', 'details', 'id', 'int', '11', 'auto_increment', 'name', 'varchar', '150', 'lastname', 'varchar', '150', 'company', 'varchar', '250', 'adress', 'varchar', '150', 'postcode', 'int', '5', 'city', 'varchar', '150', 'email', 'varchar', '250', 'phone', 'varchar', '20', 'orgnr', 'varchar', '15', 'timestamp', 'timestamp', 'current_timestamp', 'run', 'sqlquery', 'alter', 'table', 'system_customer', 'add', 'fulltext', 'name', 'lastname', 'except', 'columns', 'id', 'postcode', 'timestamp', 'signs', 'trouble', 'far', 'idea', 'problem', 'lies', 'db', 'configuration', 'php', 'code', 'goes', 'php', 'sth', 'dbhprepare', 'select', 'name', 'lastname', 'company', 'adress', 'city', 'phone', 'email', 'orgnr', 'db_pre', 'customer', 'match', 'name', 'lastname', 'company', 'adress', 'city', 'phone', 'email', 'orgnr', 'search', 'boolean', 'mode', 'bind', 'placeholders', 'sthbindparam', 'search', 'data', 'sthexecute', 'rows', 'sthfetchall', 'testing', 'print_r', 'dbherrorinfo', 'empty', 'rows', 'echo', 'else', 'echo', 'foreach', 'rows', 'row', 'echo', 'tr', 'datahref', 'new_orderphp', 'cid', 'row', 'id', 'echo', 'td', 'row', 'name', 'td', 'echo', 'td', 'row', 'lastname', 'td', 'echo', 'td', 'row', 'company', 'td', 'echo', 'td', 'row', 'phone', 'td', 'echo', 'td', 'row', 'email', 'td', 'echo', 'td', 'date', 'ymd', 'strtotime', 'row', 'timestamp', 'td', 'echo', 'tr', 'echo', 'tried', 'change', 'parameter', 'searchquery', 'string', 'like', 'testcompany', 'somename', 'boolean', 'mode', 'also', 'read', 'word', 'found', '50', 'rows', 'counts', 'common', 'word', 'pretty', 'sure', 'case', 'uses', 'specific', 'words', 'table', 'uses', 'myisam', 'engine', 'get', 'results', 'error', 'messages', 'please', 'help', 'point', 'wrong', 'thank'], tags=['Train_0']),\n",
       " TaggedDocument(words=['select', 'everything', '1', 'table', 'x', 'rows', 'another', 'im', 'making', 'join', 'query', 'like', 'select', 'clothes', 'c', 'join', 'style', 'cstyleid', 'ssylelid', 'clothesid', '19', 'dont', 'want', 'select', 'everything', 'style', 'want', 'select', 'everything', 'clothes', '20', 'rows', 'select', '1', 'row', '10', 'style', 'easyest', 'way', 'without', 'select', 'every', 'row', 'clothes', '20', 'things', 'select', 'like', 'select', 'cid', 'cdescription', 'cname', 'csize', 'cbrand', 'sname', 'clothes', 'c', 'join', 'style', 'cstyleid', 'stsylelid', 'clothesid', '19', 'would', 'fastest', 'way', 'possibillity'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 2223738.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 2354498.71it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2501672.43it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858908.05it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2501597.83it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2859151.66it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668259.62it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668599.15it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858615.78it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858615.78it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668259.62it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668386.93it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2859297.84it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858908.05it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2667750.48it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2501448.64it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668047.45it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668344.49it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668005.03it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858761.91it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858761.91it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858761.91it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668386.93it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668471.82it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2501560.53it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668344.49it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2858713.20it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668386.93it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668259.62it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2223797.25it/s]\n",
      "100%|██████████| 40000/40000 [00:00<00:00, 2668471.82it/s]\n"
     ]
    }
   ],
   "source": [
    "## initialize the model and train for 30 epochs\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8080833333333334\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         java       0.70      0.67      0.69       589\n",
      "         html       0.89      0.91      0.90       661\n",
      "      asp.net       0.93      0.95      0.94       606\n",
      "           c#       0.80      0.79      0.80       613\n",
      "ruby-on-rails       0.83      0.89      0.86       601\n",
      "       jquery       0.73      0.72      0.72       585\n",
      "        mysql       0.86      0.82      0.84       621\n",
      "          php       0.82      0.85      0.83       587\n",
      "          ios       0.71      0.68      0.69       560\n",
      "   javascript       0.66      0.65      0.65       611\n",
      "       python       0.67      0.66      0.67       593\n",
      "            c       0.82      0.84      0.83       581\n",
      "          css       0.81      0.77      0.79       608\n",
      "      android       0.84      0.84      0.84       593\n",
      "       iphone       0.84      0.81      0.83       592\n",
      "          sql       0.71      0.65      0.68       597\n",
      "  objective-c       0.85      0.86      0.85       604\n",
      "          c++       0.90      0.96      0.93       610\n",
      "    angularjs       0.94      0.96      0.95       595\n",
      "         .net       0.80      0.85      0.83       593\n",
      "\n",
      "     accuracy                           0.81     12000\n",
      "    macro avg       0.81      0.81      0.81     12000\n",
      " weighted avg       0.81      0.81      0.81     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get vectors from trained doc2vec model\n",
    "\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "\n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')\n",
    "\n",
    "\n",
    "## Now, get a logistic regression model trained by the doc2vec features\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 28000\n",
      "Test size: 12000\n",
      "x_train shape: (28000, 1000)\n",
      "x_test shape: (12000, 1000)\n",
      "y_train shape: (28000, 20)\n",
      "y_test shape: (12000, 20)\n",
      "WARNING:tensorflow:From C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\localadmin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25200 samples, validate on 2800 samples\n",
      "Epoch 1/2\n",
      "25200/25200 [==============================] - 10s 413us/step - loss: 1.0288 - acc: 0.7189 - val_loss: 0.6573 - val_acc: 0.7979\n",
      "Epoch 2/2\n",
      "25200/25200 [==============================] - 8s 337us/step - loss: 0.5706 - acc: 0.8183 - val_loss: 0.6635 - val_acc: 0.7911\n",
      "12000/12000 [==============================] - 0s 37us/step\n",
      "Test accuracy: 0.79625\n"
     ]
    }
   ],
   "source": [
    "############### Bag-of-Words (BOW) model with keras ###############\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "\n",
    "\n",
    "## Keras training & testing \n",
    "\n",
    "train_size = int(len(df) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(df) - train_size))\n",
    "\n",
    "train_posts = df['post'][:train_size]\n",
    "train_tags = df['tags'][:train_size]\n",
    "\n",
    "test_posts = df['post'][train_size:]\n",
    "test_tags = df['tags'][train_size:]\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "## Model building \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "## get score \n",
    "\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
